{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5f571a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "running on the gpu\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import torch.optim as optim                          # optimization\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm                                # for progress bar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from clustering import clus\n",
    "\n",
    "from numba import njit\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"running on the gpu\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"running on the cpu\")\n",
    "    \n",
    "from scDHA import scDHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0f9593",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scDHA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1321aeb0250e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"goolam\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdo_clus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlatent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscDHA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvae_choice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'paper'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# a list with 3 differently trained latent variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scDHA' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"goolam\"\n",
    "do_clus = True\n",
    "latent = scDHA(path, False, vae_choice='paper', retrain=True, seed=1) # a list with 3 differently trained latent variables\n",
    "print(len(latent), latent[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c474cb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "x = np.load('latent/xin.npy')\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a734cab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [1 2 3]\n",
      " [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "x = [np.array([1,2,3]), np.array([1,2,3]), np.array([1,2,3])]\n",
    "x = np.array(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33335ae",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31de9723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log2 is applied\n",
      "training non-negative kernel autoencoder\n",
      "epoch 10 Loss:  0.0033938742708414793\n",
      "epoch 10 Loss:  0.003262168727815151\n",
      "epoch 10 Loss:  0.0035166756715625525\n",
      "tensor([0.0855, 0.0570, 0.1690,  ..., 0.0709, 0.0375, 0.1040])\n",
      "training stacked bayesian autoencoder\n",
      "\n",
      "##############################\n",
      "#phase 1: the warm-up process#\n",
      "##############################\n",
      "epoch 10 Loss: 0.04290628805756569\n",
      "\n",
      "########################\n",
      "#phase 2: the VAE stage#\n",
      "########################\n",
      "epoch 10 Loss: 2.333294630050659\n",
      "epoch 20 Loss: 2.3192358016967773\n",
      "training stacked bayesian autoencoder\n",
      "\n",
      "##############################\n",
      "#phase 1: the warm-up process#\n",
      "##############################\n",
      "epoch 10 Loss: 0.041616957634687424\n",
      "\n",
      "########################\n",
      "#phase 2: the VAE stage#\n",
      "########################\n",
      "epoch 10 Loss: 2.3494277000427246\n",
      "epoch 20 Loss: 2.3272147178649902\n",
      "training stacked bayesian autoencoder\n",
      "\n",
      "##############################\n",
      "#phase 1: the warm-up process#\n",
      "##############################\n",
      "epoch 10 Loss: 0.04415293037891388\n",
      "\n",
      "########################\n",
      "#phase 2: the VAE stage#\n",
      "########################\n",
      "epoch 10 Loss: 2.3566479682922363\n",
      "epoch 20 Loss: 2.3561482429504395\n",
      "\n",
      "####################\n",
      "    accuracy: 0.97\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "from Analysis import scDHA_class\n",
    "res = scDHA_class('baron-human', seed=1, retrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbcf50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 15)\n",
      "finding best k...\n",
      "best k is 5\n",
      "running SC on k=5...\n",
      "SpectralClustering(affinity='nearest_neighbors', eigen_solver='arpack',\n",
      "                   n_clusters=5, n_jobs=-1, n_neighbors=7, random_state=0)\n",
      "(1600, 15)\n",
      "finding best k...\n",
      "best k is 5\n",
      "running SC on k=5...\n",
      "SpectralClustering(affinity='nearest_neighbors', eigen_solver='arpack',\n",
      "                   n_clusters=5, n_jobs=-1, n_neighbors=7, random_state=0)\n",
      "(1600, 15)\n",
      "finding best k...\n",
      "best k is 5\n",
      "running SC on k=5...\n",
      "SpectralClustering(affinity='nearest_neighbors', eigen_solver='arpack',\n",
      "                   n_clusters=5, n_jobs=-1, n_neighbors=7, random_state=0)\n",
      "[[1 3 3 ... 3 1 3]\n",
      " [0 0 0 ... 0 3 1]\n",
      " [2 0 2 ... 3 3 4]]\n",
      "[[ 4.09367810e-05  1.27577776e-03 -1.15296742e-03]\n",
      " [ 1.27577776e-03  6.17736990e-04  5.77433208e-04]\n",
      " [-1.15296742e-03  5.77433208e-04 -1.91844737e-04]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f7ee70b07ca2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# guess number of clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if do_clus:\n",
    "    # Use an ensemble of data projection models to achieve higher accuracy and to avoid local minima, not needed if we use kmeans++\n",
    "    # first repeat the data projection\n",
    "    labels = []\n",
    "    for hidden in latent:\n",
    "        # labels.append(clus(hidden, k=6, nmax=100))\n",
    "        labels.append(clus(hidden, nmax=50))\n",
    "    labels = np.array(labels) \n",
    "    print(labels)   \n",
    "    S = np.zeros((len(labels), len(labels)))  # chance that cell i and j are in the same cluster\n",
    "    for i, row in enumerate(S):\n",
    "        for j, _ in enumerate(S):\n",
    "            if not (i==j):\n",
    "                S[i, j] = adjusted_rand_score(labels[i], labels[j])\n",
    "    for i, row in enumerate(S):\n",
    "        S[i,i] = row.mean()\n",
    "    print(S)\n",
    "    found = False\n",
    "    if (S[S < 0.7]).sum() > 0:\n",
    "        i = 2\n",
    "    else:\n",
    "        i = 1\n",
    "        \n",
    "    # find best guessed label (latent variable)\n",
    "    while not found:\n",
    "        # print(f'i={i}')\n",
    "        tmp = KMeans(n_clusters = i, n_init = 100, max_iter = 5000).fit(S)\n",
    "        k = tmp.labels_\n",
    "        max = 0\n",
    "        for c in range(tmp.cluster_centers_.shape[0]): # for k clusters\n",
    "            score = S[k == c, k == c].mean()\n",
    "            if score > max and (k==c).sum() > 1:\n",
    "                max = score\n",
    "                idx = (k == c)\n",
    "        if max > 0.8:\n",
    "            found = True\n",
    "        if i >= 3:\n",
    "            found = True\n",
    "        \n",
    "        i += 1\n",
    "    # guess number of clusters\n",
    "    tmp = []\n",
    "    for label in labels[idx]:\n",
    "        tmp.append(np.unique(label).shape[0])\n",
    "        print(tmp)\n",
    "    cluster_max = np.floor(np.mean(tmp)+0.5).astype(np.int)\n",
    "    \n",
    "    \n",
    "    # (i) calculate cell-cell weighted similarity matrix \n",
    "    W = S * (1 - S)\n",
    "    print(W.max(), W.min())\n",
    "    # then combine the clustering results using the wMetaC\n",
    "    # wMetaC = AgglomerativeClustering(n_clusters=k_classes, linkage='ward')\n",
    "    # # wMetaC = AgglomerativeClustering(n_clusters=k_classes, affinity='precomputed')\n",
    "    # wMetaC.fit(latent)\n",
    "    # # wMetaC.fit(clustered.affinity_matrix_.toarray())\n",
    "    # print(wMetaC)\n",
    "    # print(clustered.labels_)\n",
    "    # print(wMetaC.labels_)\n",
    "\n",
    "        # print(latent.size())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab75e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training non-negative kernel autoencoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 106.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.001624945318326354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 107.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0016046841628849506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 108.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0015911390073597431\n",
      "training stacked bayesian autoencoder\n",
      "phase 1: the warm-up process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 154.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.02688029780983925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 159.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.01863638311624527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 152.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0181533545255661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 156.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.01757773384451866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 161.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.01729338802397251\n",
      "phase 2: the VAE stage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 132.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  2.0298502445220947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 140.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.9593911170959473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 116.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.9687726497650146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 139.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.9809030294418335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 146.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.951000690460205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0781,  0.0789,  0.0101,  ...,  0.0791, -0.1060,  0.0511],\n",
       "        [-0.0928,  0.0692,  0.0293,  ...,  0.0207, -0.0778,  0.0243],\n",
       "        [-0.0822,  0.0621, -0.0014,  ...,  0.0103, -0.1345,  0.0899],\n",
       "        ...,\n",
       "        [-0.0850,  0.0382, -0.0398,  ...,  0.0492, -0.0836,  0.1068],\n",
       "        [-0.0944,  0.0489, -0.0496,  ...,  0.0135, -0.0710,  0.1006],\n",
       "        [ 0.0677,  0.8861,  0.1220,  ...,  0.1088, -0.0515, -0.2227]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline('campbell', 1000, 3, False, 1000, 5, vae_choice='paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a60f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41b6c0752d4e012e3eac71aaaca6904fd15380f04bbe1ef1c7bcd4dfab5ac212"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('pyr': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
